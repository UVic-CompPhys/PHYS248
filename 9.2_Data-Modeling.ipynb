{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.2 Data modeling \n",
    "\n",
    "#### This week:\n",
    "**Miscellaneous:**\n",
    "* data storage in a pckle\n",
    "\n",
    "***Data modeling:**\n",
    "* Standard normal distribution\n",
    "* Moments of distribution\n",
    "* Least-square fitting of arbitrary curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous\n",
    "### A useful python data storgage strategy: pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "dict['set1'] = array([1,45,16])\n",
    "dict['mb2'] = {}; dict['mb2'][4]=(1,2); dict['mb2']['Paula']=5\n",
    "all = ['Orange',(3,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"datacontainer.pickle\",\"wb\")\n",
    "pickle.dump([dict,all], pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"datacontainer.pickle\",\"rb\")\n",
    "thing1,thing2 = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard normal distribution\n",
    "\n",
    "The [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) describes random processes, such as repeat measurements of a physical quantity. It plays an important role as a model distribution in many areas.\n",
    "\n",
    "Roadmap:\n",
    "1. Create data set with a normal distribution.\n",
    "2. Plot a histogram of the distribution.\n",
    "3. Overplot the properly scaled propability density of the normal distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pylab ipympl\n",
    "%pylab nbagg\n",
    "random.standard_normal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab ipympl\n",
    "\n",
    "ifig=1;close(ifig);figure(ifig)\n",
    "a=random.standard_normal((2,300))\n",
    "plot(a[0],a[1],'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the usual histogram of the distribtion. We use both `a` arrays and combine them (_loose the shape_) with the `.flatten` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifig=2;close(ifig);figure(ifig)\n",
    "#ifig=2;figure(ifig)\n",
    "n=10\n",
    "ah=hist(a.flatten(),n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution\n",
    "yh=ah[0]\n",
    "xh=ah[1][0:-1]+0.5*diff(ah[1])\n",
    "plot(xh,yh,'o--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But default `hist` will represent the number of samples in each bin. However, often it is desirable to plot the value of the probability density function at the bin, normalized such that the integral over the range is 1.\n",
    "\n",
    "Normalization of discretized distribution: $$\\zeta_\\mathrm{dens} = \\frac{(x_\\mathrm{max}-x_\\mathrm{in}) N}{n}$$ where $N$ is the number of values and $n$ is the number of bars in the histogram. Divide each bin value by $\\zeta_\\mathrm{dens}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same is accomplished with the `numpy.hist` option `density=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifig=22;close(ifig);figure(ifig)\n",
    "#ifig=2;figure(ifig)\n",
    "n=10\n",
    "ad=hist(a.flatten(),n,density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution\n",
    "yd=ad[0]\n",
    "xd=ad[1][0:-1]+0.5*diff(ad[1])\n",
    "plot(xd,yd,'o--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability density of the normal distribution\n",
    "$$ f(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp -\\frac{(x-\\mu)^2}{2\\sigma^2})$$\n",
    "where $\\mu$ is the mean, $\\sigma$ is the standard deviation and $\\sigma^2$ is the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_normal(x,mu,var):\n",
    "    '''Probaility density function of normal distribution'''\n",
    "    thing = sqrt(2*pi*var)\n",
    "    thang = -(x-mu)**2/(2.*var)\n",
    "    return exp(thang)/thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close(3);figure(3)\n",
    "xmin = ad[1][0]; xmax = ad[1][-1]\n",
    "print(xmin,xmax)\n",
    "xx = linspace(xmin,xmax,1000)\n",
    "plot(xx,pdf_normal(xx,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to discrete distribution density Figure 22\n",
    "figure(22)\n",
    "plot(xx,pdf_normal(xx,0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more, make a clean plot of PDF (probability density function) and normalized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifig=3;close(ifig);figure(ifig)\n",
    "plot(xd,yd,'o')\n",
    "plot(xx,pdf_normal(xx,0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moments of distribution\n",
    "\n",
    "**Literature:** Press etal. _Numerical Recipies_, Chapter 14.1\n",
    "\n",
    "Moments are the sums of integer powers of data values $(x_1, x_2,\n",
    "x_3, \\dots, x_\\mathrm{N})$. They characterize the distribution of\n",
    "data values if the data shows a sufficiently strong tendency to \n",
    "cluster around some particular value.\n",
    "\n",
    "### Mean\n",
    "\n",
    "$1^{st}$ moment:\n",
    "\n",
    "$$  <x> = \\bar{x} = \\frac{1}{N} \\sum_{j=1}^N x_j  $$\n",
    "\n",
    "### Variance/width\n",
    "\n",
    "$2^{nd}$ moment:\n",
    "\n",
    "$$ var(x_1, x_2, x_3, \\dots, x_N) = \\frac{1}{N-1} \\sum_{j=1}^N (x_j - \\bar{x})^2  $$\n",
    "\n",
    "and related to that the standard deviation:\n",
    "\n",
    "$$ \\sigma(x_1, x_2, x_3, \\dots, x_N) = \\sqrt{var(x_1, x_2, x_3, \\dots, x_N)} $$\n",
    "\n",
    "\n",
    "###  Skew\n",
    "\n",
    "The $3^{rd}$ moment indicates the asymmetry of the distribution in\n",
    "terms of a tilt:\n",
    "\n",
    "$$ skew(x_1, x_2, x_3, \\dots, x_N) = \\frac{1}{N} \\sum_{j=1}^N\n",
    "\\left(\\frac{x_j - \\bar{x}}{\\sigma}\\right)^3 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate mean and std deviation\n",
    "\n",
    "Write a function that will take an array of data values and calculates the mean and standard deviation. Add appropriate documentation and make sure that common user errors are escaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mean_var(x):\n",
    "    N = len(x)\n",
    "    m = sum(x)/N\n",
    "    var = sum((x-m)**2)/(N-1)\n",
    "    return m,var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mean_var(a.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# of course, libraries can do that as well: numpy\n",
    "print(mean(a.flatten()),var(a.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A skewed distribution\n",
    "Let's generate a skewed distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skew\n",
    "y = lambda x: sqrt(1-x**2)\n",
    "x=linspace(-1,1,500)\n",
    "close(115);figure(115)\n",
    "plot(x,y(x),'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close(13);figure(13)\n",
    "yh = hist(y(x),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.skew?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.skew(y(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution has\n",
    "a longer left tail and the mass of the distribution is concentrated on the right of the figure which is associated with a \n",
    "[negative skew](https://en.wikipedia.org/wiki/Skewness#/media/File:Negative_and_positive_skew_diagrams_(English).svg).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear correlation\n",
    "\n",
    "**Literature:** Press etal. _Numerical Recipies_, Chapter 14.5\n",
    "\n",
    "If we know that two data sets are correlated than the linear correlation coefficient provides a measure of how well they are correlated. This is a different question than _Are the two data sets correlated?_ - and a \n",
    "slightly modified approach is needed to answer that question; see discussion Chapter 14.5, Numerical Recipes.\n",
    "\n",
    "For $N$ pairs of values $(x_i,y_i)$ with $i=1 \\dots N$ this coefficient (also called the product-moment correlation coefficient, or _Pearson's r_) is given by\n",
    "\n",
    "$$ r = \\frac{\\sum_i (x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_i (x_i-\\bar{x})^2}\\sqrt{\\sum_i (y_i-\\bar{y})^2}}$$\n",
    "\n",
    "An example of a real-world application of the _Pearson's r_ correlation analysis can be found in this [paper](http://adsabs.harvard.edu/abs/2018JPhG...45e5203D).\n",
    "\n",
    "Let's look at two data sets, one with and one without correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level=0.4\n",
    "noisy_y=exp(-x)+noise_level*randn(len(x))\n",
    "close(19);figure(19)\n",
    "plot(x,noisy_y,'o')\n",
    "plot(x,randn(len(x)),'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strongly correlated set of data pairs\n",
    "stats.pearsonr(x,2*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a clearly uncorrelated set of data pairs\n",
    "stats.pearsonr(x,randn(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strongly correlated set of data pairs\n",
    "stats.pearsonr(x,noisy_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting data with a model \n",
    "\n",
    "**Literature:** Press etal. _Numerical Recipies_, Chapter 15.1 - 15.2\n",
    "\n",
    "#### $\\chi$-square as merit function\n",
    "Often we have some experimental data, and we have a physics based\n",
    "model in the form of a simple equation that we expect to reproduce\n",
    "trends observed in the data. The model contains undetermined\n",
    "parameters, maybe representing unresolved sub-grid physics.\n",
    "\n",
    "Again, we have $N$ pairs of values $(x_i,y_i)$ with $i=1\n",
    "\\dots N$, and we have a model in the form\n",
    "$$ y(x) = y(x; a_1 \\dots a_M)$$\n",
    "\n",
    "In order to determine the parameters $(a_1 \\dots a_M)$ that\n",
    "provide the _maximum likelyhood_ for the data to be a representation\n",
    "of the model (specified by the parameter values $a_j$) we need to\n",
    "adopt a _merit function_ that is arranged so that a minimum in the\n",
    "merit function yields the _best-fit parameters_.\n",
    "\n",
    "Such a _merit function_ may be based on the least-squares fit:\n",
    "\n",
    "mimimize over the parameter values $a_j$:\n",
    "$$ \\sum_{i=1}^N [y_i -  y(x; a_1 \\dots a_M) ]^2$$\n",
    "\n",
    "However, this does not yet include the statistical error on each\n",
    "$y_i$. Therefore we minimize instead over\n",
    "$$\\chi^2 =  \\sum_{i=1}^N \\left( \\frac{y_i -  y(x; a_1 \\dots a_M) }{\\sigma_i}\\right )^2 $$\n",
    "where $\\sigma_i$ is the standard deviation of the point $(x_i,y_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting a straight line\n",
    "\n",
    "The most simple model would involve a linear correlation\n",
    "$$ y(x) = y(x; a, b) = a + bx$$\n",
    "\n",
    "\n",
    "\n",
    "##### What is $\\chi^2$ for this model?\n",
    "$$\n",
    "\\chi^2(a,b) = \\sum_{i=1}^N \\left ( \\frac{y_i - a - bx_i}{\\sigma_i} \\right )^2\n",
    "$$\n",
    "\n",
    "##### What are the parameters $a$ and $b$?\n",
    "Derive a condition for $a$ and $b$ considering that $\\chi^2$ has a minimum with respect to $a$ and $b$ when $\\frac{\\partial \\chi^2}{\\partial a} = 0$ and $\\frac{\\partial \\chi^2}{\\partial b} = 0$\n",
    "\n",
    "With \n",
    "$$ S \\equiv \\sum_{i=1}^N \\frac{1}{\\sigma_i^2} $$\n",
    "$$ S_x \\equiv \\sum_{i=1}^N \\frac{x_i}{\\sigma_i^2}\\mathrm{,\\ } S_y \\equiv \\sum_{i=1}^N \\frac{y_i}{\\sigma_i^2} $$\n",
    "$$ S_{xx} \\equiv \\sum_{i=1}^N \\frac{x_i^2}{\\sigma_i^2}\\mathrm{,\\ } S_{xy} \\equiv \\sum_{i=1}^N \\frac{x_i y_i}{\\sigma_i^2} $$\n",
    "\n",
    "we get\n",
    "\n",
    "$$ aS +bS_x = S_y$$\n",
    "$$ aS_x + b S_{xx} = S_{xy}$$\n",
    "\n",
    "with the solution \n",
    "\n",
    "$$\\Delta  \\equiv SS_{xx} - (S_x)^2$$\n",
    "\n",
    "$$a = \\frac{S_{xx}S_y-S_xS_{xy}}{\\Delta}$$\n",
    "\n",
    "$$b = \\frac{SS_{xy}S_y-S_xS_{y}}{\\Delta}$$\n",
    "\n",
    "\n",
    "This is how you could implement this yourself.\n",
    "But this is only the first step. We would also need to determine the _goodness-of-fit_. To make it easy, let's use some libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least-square fitting of arbitrary curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=linspace(0,5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifig=5;close(ifig);figure(ifig)\n",
    "def func_explore(x):\n",
    "    return exp(-x)\n",
    "#    return x\n",
    "plot(x,func_explore(x),'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level=0.2\n",
    "noisy_y=func_explore(x)+noise_level*randn(len(x))\n",
    "figure(5)\n",
    "plot(x,noisy_y,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifig=6;close(ifig);figure(ifig)\n",
    "hist(noisy_y,6,density=True)\n",
    "#hist(func_explore(x),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "#curve_fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to fit the data with these two model functions\n",
    "def model_func(x,a,b,c):\n",
    "#    return a*x**3+b*x**2+c\n",
    "    return a*exp(b*x)+c\n",
    "fitpars, covmat = curve_fit(model_func,x,noisy_y,p0=[1.5,-1.5,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances = covmat.diagonal()\n",
    "std_devs = np.sqrt(variances)\n",
    "print(fitpars,std_devs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifig=7;close(ifig);figure(ifig)\n",
    "\n",
    "plot(x,func_explore(x),label='org function')    \n",
    "plot(x,noisy_y,'o',label='noised data')   \n",
    "plot(x,model_func(x,fitpars[0],fitpars[1],fitpars[2]),'--',\\\n",
    "     label='fitted function') # fitted model function\n",
    "legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative libraries\n",
    "\n",
    "There is another fitting method called `polyfit` in the `numpy` package. It is specifically designed to fit data with a power law. Another option is `numpy.linalg.lstsq`. You will have to try them, read the documentation of what algorithms they use, what limitations are specified and try to assess which methods best serves your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
